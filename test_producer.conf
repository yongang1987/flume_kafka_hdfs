tier1.sources  = source1
tier1.channels = channel1
tier1.sinks = sink1

tier1.sources.source1.type = exec
tier1.sources.source1.command = tail  -n +$(tail -n1 /data/flume/tail/test_producer) --max-unchanged-stats=600 -F  /data/infoc/exception/exception.log 2>&1 | awk 'ARGIND==1{i=$0;next}{i++; if($0 ~ /file truncated/ || $0 ~ /文件已截断/){i=1; print i >> "/data/flume/tail/test_producer";} else {print i >> "/data/flume/tail/test_producer"; print $1;}system("");}' /data/flume/tail/test_producer -

tier1.sources.source1.shell = /bin/bash -c
tier1.sources.source1.channels = channel1

tier1.channels.channel1.type = memory
tier1.channels.channel1.capacity = 10000
tier1.channels.channel1.transactionCapacity = 1000

tier1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
tier1.sinks.sink1.topic = test
tier1.sinks.sink1.brokerList = 10.60.82.120:9092,10.60.82.121:9092,10.60.82.122:9092
tier1.sinks.sink1.channel = channel1
tier1.sinks.sink1.batchSize = 20
